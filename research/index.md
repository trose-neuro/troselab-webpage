---
title: Research
header: images/photo.jpg
nav:
  order: 1
  tooltip: Current research themes
---

# {% include icon.html icon="fa-solid fa-microscope" %}Research

Our central question is how reliable processing emerges in dynamic neural circuits and ever-changing sensory environments.
We study the stability-plasticity conundrum across the mouse visual system, dorsal cortex, thalamus, and hippocampal formation, spanning synapses to circuits and milliseconds to months.

## Current Projects

- What are the cell-autonomous, circuit-specific, and behavioral state-dependent determinants of long-term representational stability? (Projects 1-2)
- How are spatial and contextual representations stabilized in retrosplenial cortex (RSC) during learning and memory? (Project 3)
- How is sensory processing stabilized and prioritized in natural vision during visual orienting behavior? (Project 4)

### Representational Drift and Stabilization

**Project 1.1**
We test how higher-order cortical feedback contributes to stable visual representations across dLGN, V1, and LM.
Using chronic two-photon imaging and deep-learning receptive-field models, we quantify drift under targeted perturbation of LM->V1 feedback.

**Project 1.2**
Building on prior findings of thalamic plasticity and structural retinothalamic convergence, we ask whether cortical feedback stabilizes dLGN representations over time.
This subproject is funded in the DFG SPP 2411 context.

**Project 2**
We compare experience-dependent stabilization in V1 and hippocampal CA1 using sparse manipulation of plasticity-related genes and chronic two-photon imaging.
The design contrasts active navigation and passive replay to separate task engagement effects from purely sensory effects.

### Learning and Memory Stabilization

**Project 3**
We investigate stabilization of spatial and sensory representations in RSC during memory formation, consolidation, and updating.
Using automated closed-loop tasks plus miniature two-photon imaging, we probe interactions among hippocampal inhibition, thalamic input, and subicular input to granular RSC.

### Natural Vision and Active Behavior

**Project 4**
We develop closed-loop visual orienting paradigms in freely moving mice and combine miniature two-photon imaging with gaze, pose, and egocentric scene tracking.
Current analyses target peri-saccadic modulation and predictive remapping-like computations in mouse dorsal visual circuits.

**Project 6**
We quantify how RSC and V1 encode landmark utility (visibility stability, retinal stability, value, and salience) in gaze-contingent closed-loop navigation tasks.
The objective is to define how affordance statistics shape stable versus flexible visual coding.

### Circuit Dynamics and State Modulation

**Project 5**
We test whether uncertainty-dependent behavioral states and cholinergic neuromodulation directly regulate representational drift during learning.
The project combines mesoscale and single-cell activity measurements with spatial transcriptomics in collaboration with the SFB 1771 "Brain States" initiative.

**Project 7**
We are establishing a multisensory preconditioning paradigm in virtual reality to dissect unsupervised cue association mechanisms in RSC and related cortical circuits.
This project links latent-learning behavior to cell-type-resolved circuit dynamics.

{% include section.html %}

## Methods and Experimental Strategy

- Acute and longitudinal synapse- and circuit-level optophysiology
- Miniaturized and bench-top two-photon microscopy for freely moving and head-fixed settings
- Automated closed-loop behavioral paradigms with dense multimodal tracking
- Joint computational modeling (deep nonlinear receptive-field analysis, dynamical and circuit-level models)

{% include section.html %}

## Current Development Directions

- Structural rules of stability: longitudinal mapping of synaptic structure-function relationships in stable and drifting populations
- Longitudinal closed-loop circuit mapping: patterned perturbation and readout across cortical hierarchies
- Digital twins for natural vision: deep models linking behavior, sensory history, and large-scale neural dynamics in freely moving animals

{% include section.html %}

{% include button.html link="projects" text="See project portfolio" icon="fa-solid fa-arrow-right" flip=true style="bare" %}
